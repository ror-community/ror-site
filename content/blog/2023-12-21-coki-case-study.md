+++
title = "Case Study: The COKI Open Acess Dashboard and ROR"
date = "2023-12-15"
draft = false
tags = ["Adoption", "Integrations", "Community", "Case Studies", "Open Access",]
categories = ["case-studies"]
style = "card-plain"
banner = "/img/banners/ROR_Banner-green.png"
thumb = ""
images = ['/']
author = "Amanda French"
description = ""
+++



 

{{% callout color="green" icon="no-icon" %}}

### Key quotations
 

{{% /callout %}}


### {{< figure src="/img/amanda-sq-200.png" class="round-figure" alt="Amanda French" >}} Amanda French 



### {{< figure src="" class="round-figure" alt="Cameron Neylon" >}} Cameron Neylon

Amanda French  
Thank you so much for doing this with us. Can you tell us your name, title and organization.

Cameron Neylon  
I'm Cameron Neylon, Professor of Research Communications at Curtin University, in the School of Media, Creative Arts and Social Inquiry, which is as mixed a school as it sounds like. We've got everything from social sciences to critical literary studies to people doing painting and sculpture and journalists, so it's a really mixed and diverse group. And then within that, I'm co-lead with Professor Lucy Montgomery of the Curtin Open Knowledge Initiative.

Amanda French  
Tell us about the Curtin Open Knowledge Initiative. When did that get started and why?

Cameron Neylon  
So, COKI, as we call it, started probably really in 2015 or 2016 in some ways. Lucy and I both returned to Australia having been in Europe and overseas and found the the level of conversation about open scholarship in Australia to be quite backwards and behind and kinda frustrating. And it was particularly frustrating because it was clear that this wasn't for a lack of interest or desire to move things forward. It was in large part because the leadership of universities were weren't engaging with these issues, because none of the information resources that they were using, made brought this up as an issue. Australia has is and has been particularly obsessed with university rankings. And there's a reasons in history behind that that have to do with the fact that the sector is very dependent on international students as a revenue source. But as we know, those rankings are incredibly narrow backwards looking, conservative, opaque and actually not very informative, but they certainly don't do anything to get a university to address questions of open access data sharing staff demographic diversity, or many of the kinds of issues that are that are that are bound up in this idea of open knowledge or or open research and what and what we rec eventually realized It was this gap in knowledge gap in understanding and gap in information resources. The idea was if we could do a better job of providing actionable information in the form that universities are expecting to see it, that informed them about progress towards aspects of, of open knowledge. And, and comparisons with other institutions, they then that would be one way of provoking change. We were very lucky to pitch this tour receptive Deputy Vice Chancellor for Research who just who just started. And as a result, got a lot of support from the university to take this forward. What we actually built, that's all very abstract, of course, what we started to build up was a collection of open data about institutional practice, about research outputs, open access, citations, traditional kinds of things. But also things like staff demographics and other kinds of information that we thought were relevant to this big, this big picture. We were very dependent on the growing set of open data resources that were you had been developing have continued to develop and will continue to develop. And we got we were lucky in our timing, I guess, in a sense that the, we started at a point where those open data resources were just about good enough to compete with proprietary data sources, but we're accelerating and improving at such a rate that now they are vastly superior, in almost all cases. And so as a result, we've been able to end that end with various advances in cloud infrastructure and computing allowed us to bring all of these datasets together. And so what we did was we essentially, with a goal of making the information actionable, we brought the big open data sets together other other data sources together into a cloud infrastructure into a large database, and set about building things that we thought might be useful. And like so we have the support, and financial support and resources that have gave us the luxury to do that. And let us do it properly. Rather than, you know, small projects, doing small things. And that has led us give build up to some mates, data resource, which is really powerful. But also build some of the kinds of information resources that we think are what are needed to help people navigate and make intelligent decisions about change.

Amanda French  
Amazing. So when and where did you personally first hear about ROR?

Cameron Neylon  
Um, so I guess that's kind of hard to pin down. But, so I have been invested in the idea that persistent identifiers are central to making use of open information at scale. And we've learned that over and over again, when we started, COKI, it was before, I think just before ROR existed, although there were conversations happening about heading heading in that direction. But Digital Science had made the GRID database available under an open license. So we were happy to be able to use that as a source of data as a source of information or indexing around around institutions. And of course, it was the GRID IDs were used by Microsoft Academic. And Microsoft Academic was one of our central data sources. And so, you then as as ROR, developed first as a concept and then as a reality. We were watching really that whole journey, waiting for the moment when you know, the maturity and systems were there to jump across because we obviously preferred something And that was organized through community infrastructures. And, and the thing that really pushed us across in the end, of course, was Microsoft Academic shutting down. And, and OpenAlex, stepping into that gap, specifically. And that coincided with a range of things we were doing. But actually, in the end, a lot of the architecture and systems we had to change and the move from Microsoft Academic to OpenAlex. The shift to ROR was one of the easiest ones, we in fact, just dropped the entire ROR data set into an identifier column and, and drop down. It was very simple.

Amanda French  
That's great to hear. And, of course, I'm talking to an increasing number of people who are using that OpenAlex dataset, and thereby using ROR because ROR is for institutional identifiers, the primary one that they that they use,

Cameron Neylon  
yeah, and we, I mean, we use a lot of these, I mean, what's what's central in our work is we have our datasets, we have OpenAlex, ROR, Crossref, Crossref Event Data, Open Citations, OpenAire. So I'm probably missing a few at this point that I'm not quite thinking of. PubMed. So you know, we bring all of these datasets together. And we, you know, and we organize them around community governance, persistent identifiers. And so that lets us do things like, rather than just saying, okay, what can OpenAlex tell me about DOIs iconnected with this institution, as identified by ROR. We can do that across multiple datasets. And that at the moment works most effectively for DOIs because the DOI as a standardized identifier across these systems has the widest uptake. But that also points us to what's here really powerful in terms of being able to connect these datasets up. And indeed, increasingly, the the first step we would take with integrating a new dataset if it doesn't have those standardized, persistent identifiers in it, is to do the mapping across because it's just not very useful without it. So in PubMed was was a good example of this. I was working with the other day. It has a bunch of institutional identifiers, but actually mostly the affiliation information in PubMed appears to be in the form of strings. And we just can't leverage that dataset as well as we might for organizational information. Because those links aren't there, we can hope we can leverage it really well, in terms of the publications because we've got the DOIs, for us, and increasingly, for datasets as well. But for organizational information, it's just that much weaker. So things like getting all the information for funding decisions from multiple data sets is a lot harder than it needs to be.

Amanda French  
Right. Are there any other sort of general entities that you wish were using ROR IDs more?

Cameron Neylon  
Oh, I mean, everyone. I mean, just it's just it's really difficult to describe clearly just how much of a difference it makes. And I think the web is rapidly moving towards a world where this is going to become self evident. What we see our work is when you can at least start that again. In the old days, if you wanted to ask a question you first started with, okay, which dataset should I use to answer this question? And what limitations does that dataset impose on me? With open data and cloud infrastructures and the availability of these datasets as a whole, that's not where we start to answer a question we ask, which data sets can we bring together to maximize the amount of information and the precision that we can apply to addressing this particular question or problem? And the datasets that are easy to integrate are the ones that we use. And so increasingly, you know, if there isn't a ROR ID or the ORCIDs aren't properly handled, then we just don't use the datasets. And that's yeah. And and the sort of the other side of that is, because we are operating at a fairly large scale, and then making these public information products, we get a lot of people coming back and saying, Oh, you're missing this, or that's not there, or there's something wrong here. And, and then we can feed that back, and we can feed it back really easily. So an example of this exactly with ROR. There was a university, we, which the librarians noticed on the global open access website that that's the counts of outputs seemed a bit down. And, and they looked closely at name variants. And they discovered that in fact, there was a bookstore on campus. And for some reason, you know, and this is a work in progress. OpenAlex had assigned a bunch of the outputs from that university to the bookstore. And the bookstore wasn't listed in the hierarchy for the institution. Now, if we come back to that point, that if that had been the case, we would have everything would have flowed up nicely and would have been, would have been done for us. But what that meant was, we don't find these errors. The people working with the data or making information products, we don't often find those kinds of errors at scale, they're always found by people on the ground, who know the context, and know exactly what the numbers should look like. And so we get back a couple of emails a week from various people saying this is wrong, this is under counting this is over counting is two organizations don't belong together, or all they do belong together. And it's really easy for us to pass that information back up when there are good identifiers. And we can say, No, this DOI should link to this ROR. Or this ROR should probably be a child of that ROR. And that sort of flow of curation information into the system, just combined with Yeah, the ease of use when things are easy to interconnect, I think is ultimately going to drive the sort of these little isolated, increasingly fragmentary datasets that are difficult to work with because they don't have the coverage and they don't have the interconnection, just make them less relevant in the long term.

Amanda French  
Fascinating. Well, I hope you, you and your staff, and refer those kinds of questions to ROR. Because we are always happy to make those kinds of corrections. We know that, you know, if there is a bookstore that should or should not be in the ROR record, we're happy to add that or take it out.

Cameron Neylon  
Well, and it raises lots of I mean, I think, really important questions, and, and, and the importance of community governance for these things, right. So in these cases, a lot of the a lot of the time, we have to ask, so someone tells us something's wrong. Now, sometimes that's a mistake we've made, we can correct that. Sometimes it's a mistake, as in a system problem in someone else's data system. And then we can pass that on and explain it to them. And sometimes it's it's a thing where there's reasonable grounds for disagreement. And so then the question of, and in fact, what we said in this case was, it's not our place to say whether that bookstore is part of that university, you guys have to make. And again, here's the here's the here's the email address for ROR. To when you when you figure that out. And I think that's a really important part of the whole story of of changing the way people think about corrections. So I mean, in the space of bibliometrics, and scientometrics, almost every university in the world has people whose job it is to correct the things that are wrong in Web of Science and Scopus. So this is like an extra full time person on top of the hundreds of thousands of dollars that are spent on a subscription to these products, working to help correct them. And, but that data just goes into a black hole, which which we can't reuse. And what this broader open data ecosystem if people sort of feel responsible to contribute to collectively raising the quality of it. And working with its community infrastructures, then the capacity for improving the data forever. One so that everyone's it looks better is is just huge. And it's sometimes a challenge because people are not used to feeling like they have authority. In many cases, like this was always data was always something that was done to them. And yet this is data about the stuff we are doing. Right? And the organizations that we are so. So yeah, I think it's a really interesting sort of transition to try and navigate to get everyone get more engaged in in feeling like they have a stake in making these things better. 

Amanda French  
It is interesting too, because ROR's curation model is I'm sure you know, is not. It's not as open as something like Wikipedia or Wikidata, in the sense that we curate everything. So anyone can request everything. But we evaluate that and approve or deny it. And by the way, Wikidata and Wikipedia are heavily edited. I'm always, you know, surprised that people don't know that. But it's a sort of a decentralized distributed editing model, whereas we have quite a centralized curation model, we also don't have a model where by there is a person at a particular organization who is responsible for making sure that that org, that our information is correct, we will take a request from anybody, you don't have to be affiliated with that organization. And we evaluate that based on, you know, openly available information and our own, you know, what makes sense for ROR. And I think that that model is unusual for people, they tend to, I think, have a kind of a binary notion of what authority over data, either there's a centralized authority, who is making decisions, and you are lucky, if you have any input into that, or it's something you know, that's entirely distributed and entirely communicated. And I actually really like our model, because I do think it has the best of both worlds we are, we will entertain any corrections that you wish to give us. But we do also review and curate that quite carefully.

Cameron Neylon  
Yeah, and I think I think I would agree in the sense that there's, there's clearly a tension here, right between consistency of application. And, and the scale at which the work can be done. So federated models, people assume that you know, the human what you what you might lose in precision you gain by having this massive scale of work that can be done. But what you do also do is you create a massive scale of work for corrections. Really, it works kind of in some parts of Wikipedia or Wikidata, but mainly because of the absolutely vast scale of those enterprises. And it's really, I mean, anyone who's done anything on crowdsourcing knows, it's really, really hard to replicate that level of success at a smaller scale, so the tension there of needing to have a reasonable amount of effort, reasonable application of resources, and get something out that's usable, drives you towards that to the other end of that spectrum of centralization. And indeed, I think then that's, again, where the community governance, and the model and transparency piece comes in. And it's and it's got to be flexible. A rigid, rigid -- because the other the other assumption people make is, well, why can't you could surely you can automate this or you have some sort of system that just yeah, obviously does all the checking for you. Ai, wave hands, wave hands. And actually, none of those things work, in part because there are bad actors in the system. And you're on the lookout on the lookout for that that's particularly true in terms of organizations and who they are and what they're connected with and who's connected with them. Exactly the areas where we've suffered a lot of fraud in the scholarly system. And, and, and so that's got to be managed in some way. That's, that's ideally flexible and transparent. But also trustworthy, at the end of the day, that's where you've got to you've got to be going, otherwise things just aren't usable.

Amanda French  
Can I ask, do you teach?

Cameron Neylon  
So I don't do a whole lot of teaching. My role is mainly research at least at the moment. And so and, and we also the work we do so our project and our work isn't doesn't neatly fit into a teaching program in the school that we're within. So like a lot of, I guess, multidisciplinary groups. There are challenges in terms of where we are and what we're teaching. Again, it's a peculiarity of the Australian system, that there is a tendency to separate research and teaching. And that's driven by financial, the financial model that the government imposes on Australian universities more than anything else. So, so yeah, so I think there's, there's always some some challenges around that. That said, we are in school that contains the Libraries and Information Program. And so we do teach into that, and then more broadly, into what you might call Critical Information Studies. So So I guess, if you're ever in the sciences, you probably call it data science, and have a little bit of ethics and critical theory applied with sort of, if you imagine the sort of other side of that, were starting from critical perspectives about what information is what information does and whose benefit it serves. And then teaching a bit of the technical side so that people get an understanding of how that works out in practice. And, and what the sort of nitty gritty of actually doing data analysis and visualization actually looks like and why we are why the tools are not neutral. And how these things play out in practice, and why? Yeah, it often looks like the entire world's data is is has been shoved through an Excel spreadsheet, because Excel spreadsheets are what drives what people do with data. 

Amanda French  
Right. The reason I asked is, I imagine you have fellows or postdocs, or graduate students or whatnot, working with you on your projects. But yeah, I'm just sort of curious how, how you address persistent identifiers, in particular, in any kind of passing knowledge along to the next generation, whether that's in a classroom setting or in a apprenticeship-slash-lab setting?

Cameron Neylon  
Yeah, so that's a good question. So I would start by observing that we've probably still got some work to do to deal with the current and indeed past generations, on the use of persistent identifiers. In terms of my, my colleagues more generally, we would, where we do teach it, so we have a team, we bring people into that team. And where we would, if you like, teach or educate people about this is through the practice. So we have processes by which we, you know, we write up documents and we and where they go, so we put them on Zenodo, by default, in a Zenodo community. So they get a DOI, and so they can be automatically connected to people's ORCIDs. We use the Tenzing tool to apply CRediT taxonomy when we, when we prepare things, or at least at least, we try to do that as much as possible. And so, yeah, so sort of at the, I guess, if you like the social level, we try and embed it as much as possible into what we do and how we do it. And then at a technical level, and most of our team is pretty technical, it also goes into the sort of architectural principles we have for our data structures. And so so that fits in there. In sort of more, I guess, traditional teaching, so we teach some courses or as set around data and telling stories with data. And yeah, actually introducing the concept of persistent identifiers and why they matter is always a challenge. Do you present it, you know, in kind of abstract and theoretical sense of well how the system could work. But that doesn't really speak to very many people. Or do you present it in a much more sort of practical and concrete way. And there you run up against against the fact that, at least until recently, many of these systems just didn't work as well as they might. And so I'm always reminded of the person who, when being asked to sort out their ORCID record, and upon being told this was the last time they'd need to sort out a personal profile as a researcher observed all that was what I was told the last five times, I had to do a personal profile as a researcher, and every one of those has fallen by the wayside. And now you want me to do another one. So we'll have How can you promise me another one's not going to come along next week? And and so one of the big challenges with all of these systems is they will work really well when everyone's using them. And when everyone doesn't even think about using them. Getting there as hard work. Yeah, as

Amanda French  
Yeah. And the metaphor I always think of, which is possibly a bit too simplistic, is the telephone, where you have telephone numbers, everyone needs a unique telephone number, telephones themselves increase in utility, the more people have them. And the more people have them, the more important it is that you have unique telephone numbers. And this is, if I were in a research position at a university, I would probably start doing all kinds of information, research into party lines and alphanumeric exchanges and things like that, you know, to look at the history of how we got to the globally standardized system that we have today for telephone numbers and the emergence of cell phones and disrupting of that.

Cameron Neylon  
And I guess the challenge with that, as a, I mean, thinking about this, you take that analogy through to, you know, the current world of social media, or streaming video platforms that everything's so vertically integrated, I don't know that people aren't very many people are aware of why it is that a phone number can be a standard thing, despite the fact that lots of different people make phones and lots of different carriers will carry phone calls. And similarly with email, because those things are the last residue of that in, in the world as a whole, most of the things we deal with, don't have those standardized things. So that's why they're awful, right? It's, it's why you've got three streaming subscriptions, not one TV aerial, why you've got 17, different direct message or a personal messenger accounts across multiple different services, none of which you really like to use that because there's one person who does like to use that particular one you have to have. And you know, the concept that the seemingly obvious concept that you should be able to get those messages wherever you want to, and send them to you anyone based on a standardized sort of protocol or system has partly been lost. And that's part of the the I think the battle of making the case for how these things work better, I think is, is Yeah, recalling the fact that you can in fact, make phone calls and you don't have to have an AT&T phone and British Telecom phone. And that's right.

Amanda French  
Yeah. And I think that's such a good point about looking at the failures of standardization, and they take takeover of non open commercial services, you know, for these things, because I suppose some other examples would be power systems globally, you know, when you travel from country to country, the plugs are different in the United States than they are in in Europe. And as I discovered recently in Africa, and the measurement systems, metric versus non metric, not standard everywhere you go. Even driving which side of the road you drive on and which side of the the car the steering wheel is on. All of those things are small frictions and yet they've been standardized enough to where they They work regionally. And we can see how well it would work if if they were standardized globally. Time zones? Actually, I don't, obviously, obviously, we have to have time zones, like just because of the fact of having a globe. But I keep thinking, wouldn't it be nice if everybody got rid of daylight savings so that we didn't have the problem of, you know, has such in such a country gone on daylight savings or not? Because, you know, if it were just a sort of a standard interval between each timezone and didn't change with the times it would make scheduling meetings so much easier?

Cameron Neylon  
Well, yeah, and/or also the weird time zones, as well. I mean, the power of the power ones is actually quite an interesting one, because there does seem to be an emerging plug standard, there's actually moves towards persuading everyone to just use. I mean, it's a bit ridiculous. But given that almost every device that we use, with some exceptions, but a lot can run off, five, five volts, so there's a five volt 12 volt, issue, five volt, 24 volt. But an awful lot of things could just use USB plugs. And we're sort of iterating almost towards that. Interestingly, as I think driven not by not really by by thoughtful top down standardization, but by frustration with how things because people are traveling and the struggle Yeah, struggle with the bag full of adapters that you're carrying, if you're going to more than one place. And yeah, I do actually carry around now just one or two USB adapters with swappable, swappable plugs, because that because that works reasonably well until I get to South Africa and realize that particular plug which is, yeah, like quite unusual. But yeah, I think the the there's something really interesting. I mean, the other and the other example from the power world, of course is once upon a time you couldn't take a any appliance from say, the US at 110 volts and bring it to anywhere in the world running at 240. But these days, I forgot. I mean, these days, I don't even remember that I should probably check before I plug something in with an adapter, because the transformers are all standardized to deal with both with both cases. And so you don't you don't usually have think about needing a step down transformer to actually to operate. I guess that yeah, that gets back to things like ROR as interchanges where? Yes, people can. And there are legacy systems of other identifiers systems out there. And there are there are there are systems like that perhaps ROR shouldn't cover that maybe ISNI needs to, but at least if we've got places to do lookups. And, and those are, again, centrally maintained and kept reasonably up to date, then we don't need to think too much about about that as we translate between things. What I wish we also had, and ROR does this well, and other identifier systems not as well, yet, I think but there's it's exactly this thing of collections of of objects. So the thing that I've you most of the work we do involves taking sets of research outputs and bundling them up into groups where those groups might be, they might be the outputs of a person, they might be the outputs of a project or an institution or a country, or discipline, or whatever it is, it might be. And in the institution case, and where because of the parent child relationships in the ROR schema, we can we can go up and down those hierarchies. And, and figure out you know, what's the level we want to operate at? Whereas I'd say you know, with DOIs that's not so easy because there's a there's a lot of complexity and inconsistency in the way that relationships between DOIs for collections versus DOIs for objects, and it's before I start getting annoyed about ISBN and book chapters. Project IDs, I think, are an area that's missing a lot of space and I think institutions really ought to do a much better job of lagging providing ways of interconnecting between between ORCIDs and institutions. So, see, there's lots of lots of opportunities there. And thinking carefully about those collections kind of questions, I think is, is really valuable.

Amanda French  
Maybe that's a good occasion for me to ask, what do you hope ROR does better in the future? What can we do that would make your life easier?

Cameron Neylon  
So I can't say there's there's there's very little that we we bump up against that a problem. At the moment, I think it's most of the sort of immediate issues we're facing how to deal with the challenges of actually making the interconnections. So the assignments of say, outputs to two organizations, and the heuristics involved with that, which is a hard problem to solve. So I think, really, actually, the sort of area where I can imagine the real benefits will arise. And this is yeah, this is already happening. So I think the the expansion of the set of organizations being covered is is really welcome. That when that when that when there's a new release that number clicks up and you think, Oh, I've been, I'm about my brain has about three releases behind I thought it was still in 95,000, or whatever it is. 110 115 120, something like that. I think that's, that's great. I think the questions of curation, and how to manage that those, again, really hard problems. And really glad that people are thinking hard about them. Not because I have opinions necessarily about how they should be done better. That because I know it's a hard problem. I'm glad smart people are thinking about it. I think in the quote one of the questions I have an I don't know, it's it's an issue that, again, a real challenge, both from a curation perspective, and from a schema perspective is how we can tackle the question of units within organizations, and what that looks like. Again, I've seen, I've seen that on both sides to sort of, I completely understand why people would want to run screaming in the opposite direction from even try to deal with it. And then I can see from the sort of internal analysis, we look at within institutions, how important that that capacity is to be able to do that. So I think that's an area that's really worth thinking through how to enable it. And the answer might be something like component DOIs. So actually for ROR, to not deal with that, but allow institutions to, to, to self manage, I can see also see that going horribly wrong.

Amanda French  
Right. 

Cameron Neylon  
But I'm not sure I've got I'm not sure I've got a better solution. But I can certainly see one of the things we see really frequently is is exactly the question of how could you responsively be able to reflect back to an institution, what the parts of it are looking like while having to deal with the fact that only the institution itself has any sort of real knowledge of what that looks like. And it's changing so fast. 

Amanda French  
Yes. Yeah, I know, departments in particular, will merge and change names and whatnot. And I have to tell you, I absolutely believe that there would be internal arguments at an institution about what their institutional hierarchy would be. 

Cameron Neylon  
These are real issues, right? So if you're, again, this is the thing we discovered, I mean, coming right back to the starting point of why we were doing this in the way we did. What a Vice Chancellor of university presidents sees is something like a here are the faculties. Here are the number of outputs, here are the number the citations, here's the amount of research income, it's really at a very high level. And so and those numbers are garbage for the most part. They are appallingly bad. Years out of date, and often related to an organizational structure that hasn't existed for half a decade or more. And so there's a desperate need for automating more of this, so that information will be more up to date and more responsive and more flexible. But at the same time, are people, if if heads of schools are being judged on how much research revenue they're being, they're getting assigned to them. And they're being judged on how much they're collaborating across the university.

Amanda French  
Right.

Cameron Neylon  
They've got to quietly not argue about where that money got assigned to, even if it then got spread out across multiple faculties or departments. It's a real, it's a real issue on which people's livelihoods depend. There, they're really complicated questions. And getting them wrong can break institutions. Because information has to be summarized. And it will never be. summarization is a lossy process. And so you've got to make decisions about what you lose. And what what matters. And I think that maybe that's the other piece, I think this isn't just a challenge for ROR. I mean, you talked about teaching earlier. But the question of literacy. How do we how do we raise the literacy of all the players not to the extent that they need to know the nitty gritty of all the all the details, how everything works. So they can ask intelligent questions about how the information that they're getting has been processed, and whether at least in principle, there's a transparent audit trail, they can go back and check and see how things might have looked if they if it was done differently. And again, it's something we build into pretty much everything we do now. But it's amazing, again, common in the project world not to do this university rankings, particularly bad at this thing you do if you're going to change something, is you do the next run the old way, and you do your next run the new way. And you look at how different they are. And and you make that clear and transparent. Ideally, you've got open source code, please. And there's parts of bits apart. And it's critically important, but it's amazing how rare rarely it's done, and even where it is done. Again, without community owned open indexes and infrastructures and systems, it's really hard for that to be for that to be transparent. So So yeah, these are these are the real challenges. I mean, people are exercised about artificial intelligence, and this, that and the other. But the problems aren't really to do with the scale at which these computational systems can work. They're to do with the fact that people are making decisions so far away from the point where the context and on the ground information is that the quality of the information that's going through those systems needs to be a lot higher than it is. And the consequences of getting it wrong, that entire departments get closed down, or universities shut down. Whole programs of research cease to exist. Teaching programs that you might need tomorrow are axed, because apparently, someone didn't get a job five years ago. You know, I'm, yeah, I mean, if you every time every time there's a major world event, there's a story that goes round about how someone three days earlier didn't get a grant about that particular thing, because it wasn't important. And, and suddenly it is.

Amanda French  
Yeah, yeah. Well, we can wrap up. What else would you like to say about ROR, or about your work?

Cameron Neylon  
Um, I think, at core what I would say is we, we couldn't do what we do. So we're focused on organizations and institutions. Without the underlying infrastructure that ROR provides to help us triage data from multiple data sources and to connect that around back level of organization. We couldn't do what we do. And as we sort of move forward with what we're trying to do, and try and scale up and scale out the kind of stuff we're doing, it's great to see that ROR is quite frequently a couple of steps ahead, thinking about the same problems and trying to address them as we can see coming down coming down ahead of us so, so yeah, keep keep on keeping on.

Amanda French  
We will. We are feeling good. We are hiring more curator help, and thinking about ways to scale up that curation that you noticed is so crucial. Thank you so much. Again, this has been really marvelous. I only wish we could talk for another half an hour about infrastructure, generally and Yep. It's fascinating. Thanks so much.

Cameron Neylon  
Have a good day. Yep. Go to the transcript.

Amanda French  
And yeah, and I'll get that to probably in about two weeks. Yep. All right. Thank you. All right. Bye bye.



{{% callout color="green" icon="no-icon" %}}

Questions? Want to be featured in a ROR case study? Contact <amanda@ror.org>.

{{% /callout %}}
